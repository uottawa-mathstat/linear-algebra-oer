\chapter{D\'eterminant}
\label{chapter:Fr_25-determinants}
Nous sommes sur le point de changer de vitesse, et ce de manière assez spectaculaire.  
Notre but : étant donnée une matrice $A$ carrée $n\times n$, découvrir la base de $\R^n$ la plus adaptée à la multiplication de $A$ par un vecteur (lorsque c'est possible de trouver une telle base bien sûr...).
Une telle base est appelée \defn{base de vecteurs propres} de la matrice $A$. L'adjectif «~propre~» vient du préfixe allemand «~eigen~» (c'est d'ailleurs pour cela qu'en anglais l'expression «~vecteur propre~» se dit «~eigenvector~»). Les vecteurs propres d'une matrice $A$ sont donc des vecteurs spéciaux pour cette matrice. Nous verrons que si l'on multiplie $A$ par un de ses vecteurs propres, alors on obtiendra un vecteur qui est multiple scalaire du vecteur propre qu'on avait choisi.


Pour arriver à introduire ces concepts importants, nous devons néanmoins d'abord maîtriser le calcul du
{\it déterminant} d'une matrice carrée --- et voir pourquoi c'est une quantité si intéressante à calculer.
\footnote{Il existe une formule qui généralise celle que nous avions vue pour les matrices $2\times2$ (voir le Lemme \ref{inverse2by2}). Pour le moment, recherchez sur internet \og Matrice inversible\ \fg\ et \og Matrice conjuguée~», car il existe une formule pour inverser une matrice carrée et cette formule fait intervenir ce qu'on appelle la \emph{matrice des cofacteurs} (un \defn{cofacteur} est un terme de la forme $(-1)^{i+j} \det(A_{ij})$ ; il apparaissait par exemple dans nos formules pour le déterminant).  En tant que telle, cette formule est 
vraiment inefficace pour les grandes matrices, à moins que ces dernières ne soient très \defn{creuse} (c'est-à-dire qu'elles aient beaucoup de coefficients $0$, ce qui accélère les calculs). 

Aussi, il existe également une formule appelée {\it règle de Cramer} pour trouver la solution de $A\xx=\bb$ lorsque $A$ est inversible. C'est historiquement la méthode que les mathématiciens utilisaient pour résoudre les systèmes d'équations linéaires à l'époque.
Néanmoins, de nos jours en pratique, on utilise l'algorithme d'élimination de Gauss-Jordan pour tout problème impliquant des systèmes de taille supérieure ou égale à $3 \times 3$, car même pour un système  $3 \times 3$ l'utilisation de la règle de Cramer implique de calculer {\it quatre} déterminants de matrices $3 \times 3$, ce qui est assez long... Vous n'avez peut être pas encore assez de recul pour vous rendre compte à quel point le calcul du déterminant est couteux, mais d'ici la fin du chapitre vous comprendrez mieux pourquoi il faut éviter cela autant que possible ! 

Enfin, il est intéressant de noter que les déterminants ont été découverts 
bien longtemps avant la réduction par rapport aux lignes (dans le monde occidental). À cette époque et jusqu'aux années 1900, les déterminants étaient comme un outil magique
pour obtenir toutes sortes de résultats en algèbre linéaire, c'était l'outil-roi !}



\section{Le déterminant d'une matrice carrée}

Soit $A$ une matrice carrée de taille $n\times n$.  

Lorsque $n=1$, on a $\det[a] = a$.

Lorsque $n=2$, nous avons
vu  précédemment que
$$
\det\left( \mat{a&b\\c&d} \right) = ad-bc\,.
$$
Cette formule est important pour deux raisons :
\begin{itemize}
\item raison algébrique : $ad-bc$ est le dénominateur dans la formule de l'inverse de la matrice $\scriptsize\mat{a&b\\c&d}$ --- on avait même vu qu'une matrice $A$ de taille $2\times2$ est inversible si et seulement si
si $\det(A) \neq 0$);
\item raison géométrique : sa valeur absolue $|ad-bc|$ est l'aire du parallélogramme dont les côtés sont définis par les vecteur-lignes de $A$.
\end{itemize}

\medskip
Lorsque $n=3$, on utilise le même type de formule que pour le produit vectoriel :
\begin{align*}
\det\mat{a&b&c\\d&e&f\\g&h&i} &= a\,\det\mat{e&f\\h&i} - b\,\det\mat{d&f\\g&i} + c\,\det\mat{d&e\\g&h}\\
&= a\,(ei-fh) - b\,(di-fg) +c\,(dh-eg)\,.
\end{align*}
Notez que le résultat final est à nouveau un scalaire.  La formule ci-dessus
est appelée le \emph{développement de Laplace (ou du cofacteur) selon la première ligne}\index{developpement de Laplace (ou du cofacteur) selon une ligne@développement de Laplace (ou du cofacteur) selon une ligne}.
Cette formule aussi est importante pour deux raisons :
\begin{itemize}
\item raison algébrique : nous allons bientôt montrer que $\det(A) \neq 0$ si et seulement si $A$
est inversible, et cette équivalence est vraie pour toute matrice carrée $A$ de n'importe quelle taille $n\times n$. De plus, bien que nous ne le ferons pas dans ce livre, il existe bien
une formule pour l'inverse $A^{-1}$ qui fait apparaître une fraction dont le dénominateur est $\det(A)$ ;
\item raison géométrique : $\det(A)$ est égal au produit mixte de vecteurs des vecteur-lignes de $A$, où l'on rappelle que le produit mixte de $\uu, \vv, \ww$ est $\uu \cdot (\vv \times \ww)$, et dont la valeur absolue est le volume du parallélépipède dont les côtés sont définis par $\uu, \vv, \ww$.  
\end{itemize}

Pour $n\geq 4$, la formule est récursive, ce qui signifie que vous devez calculer 
les déterminants de matrices plus petites, qui à leur tour sont calculés en termes 
de matrices encore plus petites, jusqu'à ce que finalement les matrices soient $2\times 2$ et qu'on puisse calculer la réponse.

\begin{definition}
Soit $A = [a_{ij}]$ une matrice $n\times n$ (ce qui veut dire que l'entr\'ee $(i,j)$ de $A$ est $a_{ij}$).
Alors on d\'efinit le d\'eterminant de $A$ par
$$
\det A = a_{11}\det(A_{11}) - a_{12}\det(A_{12}) + \cdots + (-1)^{1+n}a_{1n}\det(A_{1n})\,,
$$
o\`u $A_{ij}$ est la sous-matrice $(n-1)\times(n-1)$  obtenue à partir de $A$ en \'eliminant la $i$-\`eme ligne et la $j$-\`eme colonne. (Remarque : il y a des signes «~$-$~» un terme sur deux dans la formule !)
\end{definition}

\begin{myexample}
Calculons $\det(A)$ pour
$$
A= \mat{
2 & 3 & 4 & 5 \\ 
1 & 0 & 0 & 1\\ 
0 & 1 & 0 & 1\\ 
0 & 0 & 1 & 0}\,.
$$
Par la formule de la définition :
$$
\det A = 2\,\det\mat{0&0&1\\ 1&0&1\\ 0&1&0} - 3\,\det\mat{1&0&1\\0&0&1\\0&1&0} +
4\,\det\mat{1&0&1\\ 0&1&1\\ 0&0&0} - 5\,\det\mat{1&0&0\\0&1&0\\0&0&1}\,.
$$
Ensuite, pour calculer chacun des d\'eterminants $3\times 3$, nous utilisons à nouveau la formule (bien que,
pour gagner du temps, nous écrivons simplement $(\cdots)$ à la place du sous-déterminant lorsque
le coefficient est $0$ devant) :
$$
\det\mat{0&0&1\\ 1&0&1\\ 0&1&0} = 0 (\cdots) - 0(\cdots) + 1\det\mat{1&0\\0&1} = 1(1-0) = 1
$$
$$
\det\mat{1&0&1\\0&0&1\\0&1&0} = 1\det\mat{0&1\\1&0} - 0 (\cdots) + 1\det\mat{0&0\\0&1} = 1(0-1) + 1(0-0) = -1
$$
$$
\det\mat{1&0&1\\ 0&1&1\\ 0&0&0} = 1\det\mat{1&1\\0&0} -0 (\cdots) + 1\det\mat{0&1\\0&0} = 0
$$
$$
\det\mat{1&0&0\\0&1&0\\0&0&1} = 1\det\mat{1&0\\0&1} - 0 + 0 = 1\,.
$$
Donc notre r\'eponse finale est
$$
\det(A) = 2(1)-3(-1) + 4(0) - 5(1) = 0\,,
$$
ce qui est plutôt intéressant.  Remarquez que la matrice $A$ n'est pas
inversible pour les raisons \'equivalentes suivantes: 
\begin{itemize}
	\item les lignes de $A$ sont linéairement dépendantes ($L_1=2L_2+3L_3+4L_4$) ; 
	\item les colonnes de $A$ sont linéairement dépendantes
 ($C_4=C_1+C_2+C_3$) ; 
 	\item le noyau de $A$ est non trivial; 
	\item le rang de $A$ est strictement inférieur à $4$.
\end{itemize}
\end{myexample}

Notez que cette formule fonctionne très bien, mais c'est une vraie torture de l'utiliser !\!!  
Pour calculer le déterminant d'une matrice $3\times 3$, il y a $3!=1\times 2\times 3=6$ produits de 3 termes à calculer, soient $2\times 3!$ produits
(on ne comptant que la partie difficile, la multiplication, sans compte l'addition).  Ok bon c'est faisable pour une matrice $3\times 3$. Mais pour une matrice $4\times 4$
c'est $3\times 4!=72$ produits à calculer puis à additionner... Ça commence à faire beaucoup...
Pire encore, pour une matrice $10\times 10$, il y a
$$
9\times 10! = 32,659,200  
$$
multiplications à faire puis à additionner... Wow... Et pour une matrice $100 \times 100$, vous devez calculer environ $9 \times 10^{159}$ multiplications... Bon là, je pense qu'on n'a plus besoin d'aller plus loin ! Amusez-vous à calculer combien de temps vous prendriez pour le calculer si
vous utilisiez l'ordinateur le plus puissant du moment  (Fugaku 415-PFLOPS\footnote{En  2020: voir {\color{blue}\url{https://fr.wikipedia.org/wiki/Fugaku_415-PFLOPS}}}), qui peut pourtant
effectuer un nombre absolument stupéfiant de calculs par seconde: $415.5\times  10^{15}$.
(Indice : il n'y a qu'environ $\pi \times 10^{7}$ secondes dans une année....).

Heureusement (et remarquablement), il existe de merveilleux raccourcis !\!!

\section{Raccourci 1: d\'evelopper selon n'importe quelle colonne ou ligne}

\begin{theorem}[Développement de Laplace selon une ligne ou une colonne quelconque]\index{calcul du déterminant par développement de Laplace ou de cofacteurs selon une ligne ou une colonne quelconque}
Soit $A = [a_{ij}]$ une matrice $n\times n$.  Alors le déterminant peut être calculé par le \emph{développement de Laplace (ou de cofacteurs)
selon la $i$-\`eme ligne}, pour n'importe quel $i$, grâce à la formule suivante :
$$
\det(A) = (-1)^{i+1}a_{i1}\det(A_{i1}) + (-1)^{i+2}a_{i2}\det(A_{i2}) + \cdots + (-1)^{i+n}a_{in}\det(A_{in})\,.
$$
De m\^eme, le déterminant peut être calculé par le \emph{développement de Laplace (ou de cofacteurs)
selon la $j$-\`eme colonne}\index{developpement de Laplace (ou de cofacteurs)
selon une colonne@développement de Laplace (ou de cofacteurs)
selon une colonne}, pour n'importe quel $j$, par la formule suivante:
$$
\det(A) = (-1)^{1+j}a_{1j}\det(A_{1j}) + (-1)^{2+j}a_{2j}\det(A_{2j}) + \cdots + (-1)^{n+j}a_{nj}\det(A_{nj}).
$$
\end{theorem}

\standout{Astuce : les signes que vous devez utiliser (c'est-à-dire les facteurs $(-1)^{i+j}$ dans
le d\'eveloppement en cofacteurs) peuvent \^etre obtenus par ce qu'on appelle \defn{la matrice des signes} associ\'ee \`a $A$:
$$
\mat{
+ & - & + & - & + & \cdots \\
- & + & - & + & - & \cdots \\
+ & - & + & - & + & \cdots \\
- & + & - & + & - & \cdots\\
\vdots & \vdots & \vdots & \vdots & \vdots & \ddots}\,.
$$}


\begin{myexample} Calculons
$$\det\mat{2 & 3 & 4\\ 1 & 0 & 3\\ 2 &0 & 4}\,.$$
Nous pouvons faire cela avec un développement de Laplace selon la première ligne :
$$
\det(A)=2\det\mat{0&3\\0&4} - 3\det\mat{1&3\\2&4}+4\det\mat{1&0\\2&0}
= 2(0) - 3(4-6) +4(0) = 6\,.
$$
D'onc $\det(A) =6$. Autre méthode : plus astucieusement, pourquoi ne pas choisir la ligne ou la colonne avec le plus grand nombre de $0$ ?  Par exemple,
la colonne 2 :
$$
\det(A) = -3\det\mat{1&3\\2&4} + 0 - 0 = 6\,.
$$
On a bien obtenu le même résultat, mais beaucoup plus rapidement !
\end{myexample}

\standout{Moralité : choisissez la ligne ou la colonne avec le plus grand nombre de zéros pour faire votre d\'eveloppement de Laplace selon cette ligne / colonne.}

Le théorème admet aussi quelques conséquences immédiates :

\begin{proposition}[Propriétés immédiates du déterminant]
Soit $A$ une matrice $n\times n$.
\begin{enumerate}
\item Si $A$ admet une colonne ou une ligne nulle, alors $\det(A) = 0$.
\item $\det(A) = \det(A^T)$.
\end{enumerate}
\end{proposition}

\begin{proof}
(1) Effectuez le développement selon cette ligne ou colonne; tous les termes sont donc nuls.

(2) Faire le développement selon la ligne $1$ de $A$ implique le même calcul \`a faire dans le développement selon la colonne $1$ de $A^T$, et par le théorème vous obtenez la même réponse. 
\end{proof}


\begin{myexample}
Calculons
$$
\det \mat{
2 & 2 & 4 & 7 & 6\\
0 & -3 & 7 & 1 & 3\\
0 & 0 & 1 & 12 & -8\\
0 & 0 & 0 & -2 & 21\\
0 & 0 & 0 & 0  & 3}\,.
$$
Cette matrice est de grande taille, nous devons être astucieux dans le choix des lignes et colonnes par lesquelles nous allons calculer $\det$. La colonne $1$ contient beaucoup de $0$, donc développons par rapport à cette colonne :
\begin{align*}
\det A &= 2 \det\mat{-3 & 7 & 1 & 3\\ 0 & 1 & 12 & -8 \\ 0 & 0 & -2 & 21\\ 0 & 0 & 0 & 3} \\
&= 2 (-3) \det\mat{1 & 12 & -8\\ 0 & -2 & 21\\ 0 & 0 & 3}\\
&= 2(-3)(1) \det\mat{-2 & 21 \\ 0 & 3}\\
&= 2(-3)(1)(-2)(3)\,.
\end{align*}
En fait, on obtient le produit des éléments de la diagonale (principale) !
\end{myexample}

\begin{proposition}[Déterminant des matrices triangulaires]
Le déterminant d'une matrice triangulaire est le produit
des entrées de la diagonale.
\end{proposition}

Mais attendez! Les ME et MER sont triangulaires ! Merveilleux, cette
proposition s'applique donc aux ME et aux MER.  En réfléchissant aux différentes possibilités, nous
concluons que : si $A$ est sous une MER, alors :
\begin{itemize}
\item soit le rang de $A$ est $n$ et le d\'eterminant de $A$ est \'egal \`a 1;
\item soit le rang de $A$ est strictement inf\'erieur \`a $n$ et le d\'eterminant de $A$ est \'egal \`a 0.
\end{itemize}
Très bien!  Mais voici une questions naturelle qui découle de cette remarque : y a-t-il un lien encore plus étroit entre $\det$ et la réduction par rapport aux lignes ?

\section{Raccourci 2:  utiliser la réduction par rapport aux lignes}

Il s'avère que OUI, vous pouvez utiliser la réduction par rapport aux lignes, à condition de
garder une trace de vos pas.  Le miracle est que notre étape favorite et
la plus utile, l'étape d'élimination n'affecte pas le déterminant !

\begin{theorem}[Déterminant après réduction par rapport aux lignes]\index{effet des op\'erations \'el\'ementaires sur les lignes sur le déterminant}
Soit $A$ une matrice $n\times n$. Nous voulons effectuer une opération élémentaire sur les lignes de $A$ pour obtenir une matrice $B$.  Alors :
\begin{enumerate}[(1)]
\item si nous \emph{échangeons deux lignes},
alors $\det(B) = -\det(A)$;
\item si nous \emph{multiplions une ligne par un scalaire non nul $k$},
alors $\det(B) = k\det(A)$;
\item si nous \emph{ajoutons \`a une ligne le multiple d'une autre ligne}, alors $\det(B) = \det(A)$.
\end{enumerate}
\end{theorem}

\begin{remark} 
Ce théorème reste vrai si le mot \og ligne\ \fg\ est remplacé par le mot \og colonne\ \fg, car $\det(A)=\det(A^T)$ et donc les op\'erations \'el\'ementaires sur les lignes de $A$ reviennent au même que les op\'erations \'el\'ementaires sur les colonnes de $A^T$. 
\end{remark}
\begin{myprob}
Calculez $\det(A)$, o\`u 
$$
A = \mat{2 & 1 & 3 & 5 \\ 1 & 2 & 3 & 1\\ 0 & 1 & 2 & 3\\ 0 & 3 & 1 & 4}\,.
$$

\begin{mysol}
Réduisons $A$ par rapport aux lignes et gardons trace de nos opérations :
$$
\mat{
2 & 1 & 3 & 5 \\ 
1 & 2 & 3 & 1\\ 
0 & 1 & 2 & 3\\ 
0 & 3 & 1 & 4}
\mt{L_1 \leftrightarrow L_2 \\ \sim}
\mat{
1 & 2 & 3 & 1\\ 
2 & 1 & 3 & 5 \\ 
0 & 1 & 2 & 3\\ 
0 & 3 & 1 & 4}
\mt{ -2L_1+L_2 \\ \sim \\ -3L_3+L_4}
\mat{
1 & 2 & 3 & 1\\ 
0 & -3 & -3 & 3 \\ 
0 & 1 & 2 & 3\\ 
0 & 0 & -5 & -5}
$$
$$
\mt{L_2\leftrightarrow L_3\\ \sim \\ -\frac13L_3\\ -\frac15 L_4}
\mat{ 
1 & 2 & 3 & 1\\ 
0 & 1 & 2 & 3\\ 
0 & 1 & 1 & -1 \\
0 & 0 & 1 & 1}
\mt{-L_2+L_3\\ \sim}
\mat{ 
1 & 2 & 3 & 1\\ 
0 & 1 & 2 & 3\\ 
0 & 0 & -1 & -4 \\
0 & 0 & 1 & 1}
\mt{\sim \\ L_3+L_4}
\mat{
1 & 2 & 3 & 1\\ 
0 & 1 & 2 & 3\\ 
0 & 0 & -1 & -4 \\
0 & 0 & 0 & -3}=R\,.
$$
Voyons maintenant ce que nos opérations ont donné.
La dernière matrice $R$ a un déterminant \'egal \`a $3$ (on obtient ce résultat rapidement, en multipliant les
entrées de la diagonale, car cette matrice est triangulaire).  Les seules opérations qui ont changé
la valeur du déterminant sont les \'echanges de lignes (pour chacune, on multiplie le déterminant par $-1$) et les
multiplications par scalaires de lignes (pour chacune, on multiplie le déterminant par le scalaire par lequel on a multiplié). 
Ainsi :
$$
\det(R) = (-1)(-\frac13)(-\frac15)(-1)\det(A)
$$
ce qui donne
$$
\det(A) = 15\,\det(R) = 45.
$$
Vous pouvez v\'erifier cela en utilisant le d\'eveloppement de Laplace, et vous verrez qu'on a bien obtenu le bon résultat.
\end{mysol}\end{myprob}

\standout{Note : si vous avez réduit par rapport aux lignes et gardé trace de
vos opérations, alors le déterminant peut être calculé sans travail supplémentaire.}

\section{Propriétés du déterminant}

\begin{theorem}[Propriétés du déterminant]\index{propriétés du déterminant}
Soient $A$ et $B$ des matrices $n\times n$.  Alors:
\begin{enumerate}[(1)]
\item $\det(kA) = k^n\det(A)$;
\item $\det(AB) = \det(A)\det(B)$;
\item $\det(A) = 0$ si et seulement si $A$ n'est pas inversible;
\item si $A$ est inversible, alors $\det(A^{-1}) = \frac{1}{\det(A)}$.
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}[(1)]
	\item Multiplier la matrice entière par un scalaire $k$ revient à multiplier chacune des $n$ lignes de $A$ par $k$. Or, chacune de ces opérations élémentaires g\'en\`ere un facteur $k$. D'où le facteur $k^n$.
(D'un point de vue géométrique : le volume d'un cube $n$-dimensionnel est dilaté d'un facteur $k^n$ lorsque vous dilatez chaque c\^ot\'e d'un facteur $k$).

	\item Cela demande un certain effort pour le prouver, mais n'est pas du tout hors de notre portée.\footnote{Pour une r\'eference, voir Lay, 
\emph{Alg\`ebre lin\'eaire et applications}. }

	\item Nous venons de voir que la réduction par rapport aux lignes peut changer la valeur du 
déterminant par un facteur \stress{non-nul}.  Ainsi, on a $\det(A) = 0$
si et seulement si $\det(R) = 0$, où $R$ est la MER de $A$.
Et comme nous l'avons remarqué précédemment : $\det(R)=0$ si et seulement si $\rank(A)<n$, ce qui n'arrive que si $A$ n'est pas inversible.

	\item Si $A$ est inversible, alors $AA^{-1} = I_n$ et, par la partie (2), on a donc
$\det(A) \det(A^{-1}) = \det(I_n) = 1$.
\end{enumerate}
\end{proof} 








